## Config

  \- model name: monologg/koelectra-base-v3-discriminator  
  \- architectures: ElectraForTokenClassification  
  \- attention probs dropout prob: 0.1  
  \- embedding size: 768  
  \- hidden act: gelu  
  \- hidden dropout prob: 0.1  
  \- hidden size: 768  
  \- max position embeddings: 512  
  \- num attention heads: 12  
  \- num hidden layers: 12  
  \- vocab size: 35000  
  
  \- train epoch: 2    
  \- learning rate: 5e-5  
  \- optimizer: AdamW  
  \- train batch size: 8  
  \- eval batch size: 8  
  
## Datasets size
  \- Train : 389,505  
  \- Dev : 55,643  
  \- Test : 111,289 (Not Used)  
  
## Results (Dev)
  - epoch 1

|           | precision | recall  | f1-score  | support |
| :-------: | :-------: | :-----: | :-------: | :-----: |
| AF        |  0.23     | 0.36    | 0.28      | 6252    |
| AM        |  0.73     | 0.87    | 0.80      | 4150    |
| CV        |  0.68     | 0.86    | 0.76      | 15257   |
| DT        |  0.85     | 0.94    | 0.89      | 7245    |
| EV        |  0.34     | 0.36    | 0.35      | 626     |
| FD        |  0.77     | 0.74    | 0.75      | 170     |
| LC        |  0.69     | 0.93    | 0.79      | 7918    |
| MT        |  0.49     | 0.67    | 0.57      | 162     |
| OG        |  0.31     | 0.70    | 0.43      | 6139    |
| PS        |  0.49     | 0.73    | 0.59      | 17561   |
| PT        |  0.52     | 0.66    | 0.58      | 901     |
| QT        |  0.73     | 0.85    | 0.79      | 4867    |
| TI        |  0.86     | 0.92    | 0.89      | 1934    |
| TM        |  0.38     | 0.75    | 0.51      | 3888    |
| TR        |  0.48     | 0.33    | 0.39      | 134     |
|           |           |         |           |         |
| micro avg | 0.55      | 0.78    | 0.64      | 77204   |
| macro avg | 0.57      | 0.71    | 0.62      | 77204   |
| weighted avg | 0.58   | 0.78    | 0.66      | 77204   |
  
  - epoch 2
  
|           | precision | recall  | f1-score  | support |
| :-------: | :-------: | :-----: | :-------: | :-----: |
| AF        |  0.05     | 0.40    | 0.09      | 6252    |
| AM        |  0.73     | 0.87    | 0.79      | 4150    |
| CV        |  0.31     | 0.85    | 0.45      | 15257   |
| DT        |  0.74     | 0.95    | 0.83      | 7245    |
| EV        |  0.12     | 0.29    | 0.17      | 626     |
| FD        |  0.71     | 0.72    | 0.72      | 170     |
| LC        |  0.29     | 0.93    | 0.44      | 7918    |
| MT        |  0.48     | 0.61    | 0.54      | 162     |
| OG        |  0.07     | 0.60    | 0.12      | 6139    |
| PS        |  0.09     | 0.74    | 0.16      | 17561   |
| PT        |  0.61     | 0.61    | 0.61      | 901     |
| QT        |  0.57     | 0.86    | 0.68      | 4867    |
| TI        |  0.74     | 0.92    | 0.82      | 1934    |
| TM        |  0.23     | 0.77    | 0.36      | 3888    |
| TR        |  0.24     | 0.37    | 0.29      | 134     |
|           |           |         |           |         |
| micro avg | 0.17      | 0.78    | 0.276      | 77204   |
| macro avg | 0.40      | 0.70    | 0.47      | 77204   |
| weighted avg | 0.30   | 0.78    | 0.40      | 77204   |

## TO DO
  
  - epoch 1 -> 2 에서 precision이 매우 떨어졌다.  
  해당 원인은 torchcrf.CRF()를 사용하기 위해 special token을 -100 에서 다시 0 으로 변경한 것이 원인으로 생각된다.  
  따라서 special token \[SEP\], \[CLS\], \[PAD\]는 label에 -100으로 처리하도록 수정하고 이를 torchcrf.CRF()에서 사용할 수 있게 하기 위해 crf 코드 수정이 필요하다고 판단하여 수정 후 다시 fine-tunning 진행 중.
  
  - 참고
    - [HuggingFace Transformers](https://huggingface.co/docs/transformers/custom_datasets#tok-ner)
    - [ELECTRA_CRF](https://github.com/Hanlard/Electra_CRF_NER)
